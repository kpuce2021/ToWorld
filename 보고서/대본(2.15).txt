안녕하세요
3조 발표 시작하겠습니다.

저희는 청각 장애인을 위한 스마트 스피커 어플을 주제로 구현중에 있습니다


저희 Sprint를 보여드리면

선배님 코드의 문제점을 찾아서 개선하려고 하고 있고
파이어베이스 공부 코틀린 공부와 병행하여 구현을 동시에 실행하고 있습니다.
그리고 CNN 알고리즘 공부를 어느정도 하였고 실질적인 구현을 시작하려고 합니다.

저희 깃허브 상태이고 현재 뒤에서 보여드릴 안드로이드 프로젝트와 CNN 테스트를 해본
파이썬 파일이 업로드 된 상태입니다. 뿐만 아니라 Firebase, Github 사용법 등 공부한 내용도
함께 업로드하고 있습니다.

종합 설계 진행 사항입니다.
저번 진행상황을 말씀드리면
저희가 데이터 셋 확보를 하고 있었는데 받아보니 목적에 맞는 데이터가 아니어서 저희가
녹음을 했습니다. 

그리고 기존 선배님들은 거실 불켜를 악 , 거실 불 꺼를 악악 이런 식으로 대체해서 템플릿
데이터를 구성해 놓았는데 저희는 원래 음성대로 템플릿을 구성해 놓았습니다.


그리고 거실 불켜, tv 켜줘, 오늘 날씨 알려줘 이렇게 3가지 명령어를 일단 CNN 테스트
용도로 녹음을 했고 이를 test와 train으로 나누어서 정확도를 측정해보았습니다.

기능 구현 정도를 먼저 보여드리면
현재 회원가입과 녹음, 녹음된 파일이 자동으로 Firebase에 업로드 되도록 구현이 되었습니다
녹음된 파일이 사용자 별로 관리가 되도록도 하였습니다.
현재 녹음된 파일을 python에서 불러오는 방법을 고안중이며
실시간으로 파일이 업로드 될 때마다 불러와야 하기 때문에 python에서 어떻게 서버를
돌려야할까 고민 중에 있습니다.


다음은 CNN 부분 입니다. 
저희 CNN은 Keras를 사용할 예정입니다.
일단 보이는 것은 Test data와 Train data입니다 Test data는 20개 Train data는 160개 정도로
구성이 되어 있습니다.

Test data가 입력되면 Train으로 학습된 데이터가 얼마나 예측을 잘하는지에 대한 
정확도를 보여줍니다. epoch가 반복될수록 정확도가 올라가는 것을 알 수 있습니다.

다시한번 정리하자면 
현재 Keras를 사용한 CNN 테스트 완료
어플의 디자인이나 Firebase 파일 접근에 관한게 완료되었습니다.

이번 주의 Sprint는 
Keras에서 데이터 삽입 후 중간 단계( 최적의 Filter 찾기, 컨볼루션 풀링 구성)
을 할 것이고 직접 어플을 구동해서 python 서버까지 전송할 수 있도록 해볼 것입니다. 

이상입니다