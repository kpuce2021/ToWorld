{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras import Input\n",
    "import sys,os,math,pathlib\n",
    "from tensorflow import keras\n",
    "from keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "split_percent=0.3\n",
    "rand_seed=123\n",
    "shuffle_num=1000\n",
    "EPOCHS=100\n",
    "dir_path = 'E:/##kpu_capstone_voice_data/##same_amount_voice/augment_bad_o(per_560)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 현재 데이터 클래스 1개 추가된 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(dir_path)\n",
    "image_list = list(data_dir.glob('*/*.png'))\n",
    "image_size = Image.open(image_list[0]).size\n",
    "img_width=image_size[0]\n",
    "img_height=image_size[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3847 files belonging to 8 classes.\n",
      "Using 2693 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=split_percent,\n",
    "    subset=\"training\",\n",
    "    seed=rand_seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3847 files belonging to 8 classes.\n",
      "Using 1154 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=split_percent ,\n",
    "    subset=\"validation\",\n",
    "    seed=rand_seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(shuffle_num).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call_sangho',\n",
       " 'good_morning',\n",
       " 'how_working_path',\n",
       " 'recommend_music',\n",
       " 'today_weather',\n",
       " 'tomorrow_weather',\n",
       " 'tv_on',\n",
       " 'youtube_dongbinna']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names  # 데이터 클래스가 1개 추가된 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 200, 260, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 206, 266, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 100, 130, 64) 9472        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 100, 130, 64) 256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 100, 130, 64) 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 102, 132, 64) 0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 50, 65, 64)   0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 50, 65, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 50, 65, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 50, 65, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 50, 65, 64)   36928       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 50, 65, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 50, 65, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 50, 65, 256)  16640       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 50, 65, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 50, 65, 256)  1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 50, 65, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 50, 65, 256)  0           batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 50, 65, 256)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 50, 65, 64)   16448       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 50, 65, 64)   256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 50, 65, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 50, 65, 64)   36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 50, 65, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 50, 65, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 50, 65, 256)  16640       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 50, 65, 256)  1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 50, 65, 256)  0           batch_normalization_60[0][0]     \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 50, 65, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 50, 65, 64)   16448       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 50, 65, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 50, 65, 64)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 50, 65, 64)   36928       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 50, 65, 64)   256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 50, 65, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 50, 65, 256)  16640       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 50, 65, 256)  1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 50, 65, 256)  0           batch_normalization_63[0][0]     \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 50, 65, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 25, 33, 128)  32896       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 25, 33, 128)  512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 25, 33, 128)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 25, 33, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 25, 33, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 25, 33, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 25, 33, 512)  66048       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 25, 33, 512)  131584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 25, 33, 512)  2048        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 25, 33, 512)  2048        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 25, 33, 512)  0           batch_normalization_66[0][0]     \n",
      "                                                                 batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 25, 33, 512)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 25, 33, 128)  65664       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 25, 33, 128)  512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 25, 33, 128)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 25, 33, 128)  147584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 25, 33, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 25, 33, 128)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 25, 33, 512)  66048       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 25, 33, 512)  2048        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 25, 33, 512)  0           batch_normalization_70[0][0]     \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 25, 33, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 25, 33, 128)  65664       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 25, 33, 128)  512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 25, 33, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 25, 33, 128)  147584      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 25, 33, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 25, 33, 128)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 25, 33, 512)  66048       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 25, 33, 512)  2048        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 25, 33, 512)  0           batch_normalization_73[0][0]     \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 25, 33, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 25, 33, 128)  65664       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 25, 33, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 25, 33, 128)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 25, 33, 128)  147584      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 25, 33, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 25, 33, 128)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 25, 33, 512)  66048       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 25, 33, 512)  2048        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 25, 33, 512)  0           batch_normalization_76[0][0]     \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 25, 33, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 13, 17, 256)  131328      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 13, 17, 256)  1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 13, 17, 256)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 13, 17, 256)  590080      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 13, 17, 256)  1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 13, 17, 256)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 13, 17, 1024) 263168      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 13, 17, 1024) 525312      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 13, 17, 1024) 4096        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 13, 17, 1024) 4096        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_79[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 13, 17, 1024) 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 13, 17, 256)  262400      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 13, 17, 256)  1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 13, 17, 256)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 13, 17, 256)  590080      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 13, 17, 256)  1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 13, 17, 256)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 13, 17, 1024) 263168      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 13, 17, 1024) 4096        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_83[0][0]     \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 13, 17, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 13, 17, 256)  262400      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 13, 17, 256)  1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 13, 17, 256)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 13, 17, 256)  590080      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 13, 17, 256)  1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 13, 17, 256)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 13, 17, 1024) 263168      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 13, 17, 1024) 4096        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_86[0][0]     \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 13, 17, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 13, 17, 256)  262400      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 13, 17, 256)  1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 13, 17, 256)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 13, 17, 256)  590080      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 13, 17, 256)  1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 13, 17, 256)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 13, 17, 1024) 263168      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 13, 17, 1024) 4096        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_89[0][0]     \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 13, 17, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 13, 17, 256)  262400      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 13, 17, 256)  1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 13, 17, 256)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 13, 17, 256)  590080      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 13, 17, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 13, 17, 256)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 13, 17, 1024) 263168      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 13, 17, 1024) 4096        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_92[0][0]     \n",
      "                                                                 activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 13, 17, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 13, 17, 256)  262400      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 13, 17, 256)  1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 13, 17, 256)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 13, 17, 256)  590080      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 13, 17, 256)  1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 13, 17, 256)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 13, 17, 1024) 263168      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 13, 17, 1024) 4096        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_95[0][0]     \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 13, 17, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 7, 9, 512)    524800      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 7, 9, 512)    2048        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 7, 9, 512)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 9, 512)    2359808     activation_89[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 7, 9, 512)    2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 9, 512)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 9, 2048)   1050624     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 9, 2048)   2099200     activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 7, 9, 2048)   8192        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 7, 9, 2048)   8192        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_98[0][0]     \n",
      "                                                                 batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 9, 2048)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 9, 512)    1049088     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 7, 9, 512)    2048        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 9, 512)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 9, 512)    2359808     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 7, 9, 512)    2048        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 9, 512)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 9, 2048)   1050624     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 7, 9, 2048)   8192        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_102[0][0]    \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 9, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 9, 512)    1049088     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 7, 9, 512)    2048        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 9, 512)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 9, 512)    2359808     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 9, 512)    2048        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 9, 512)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 9, 2048)   1050624     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 9, 2048)   8192        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_105[0][0]    \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 9, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            14343       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,602,055\n",
      "Trainable params: 23,548,935\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K = num_classes\n",
    "input_tensor = Input(shape=(img_height, img_width, 3), dtype='float32', name='input')\n",
    "def conv1_layer(x):    \n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x) \n",
    "    return x    \n",
    "def conv2_layer(x):         \n",
    "    x = MaxPooling2D((3, 3), 2)(x)      \n",
    "    shortcut = x\n",
    "    for i in range(3):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)            \n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    " \n",
    "        else:\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])   \n",
    "            x = Activation('relu')(x)  \n",
    "            shortcut = x            \n",
    "    return x\n",
    " \n",
    "def conv3_layer(x):        \n",
    "    shortcut = x    \n",
    "    \n",
    "    for i in range(4):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)    \n",
    " \n",
    "            shortcut = x              \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])     \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    "            \n",
    "    return x\n",
    "\n",
    "def conv4_layer(x):\n",
    "    shortcut = x        \n",
    "  \n",
    "    for i in range(6):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    " \n",
    "    return x\n",
    "\n",
    "def conv5_layer(x):\n",
    "    shortcut = x    \n",
    "  \n",
    "    for i in range(3):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])  \n",
    "            x = Activation('relu')(x)      \n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)           \n",
    "            \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)       \n",
    " \n",
    "            shortcut = x                  \n",
    " \n",
    "    return x\n",
    "\n",
    "x = conv1_layer(input_tensor)\n",
    "x = conv2_layer(x)\n",
    "x = conv3_layer(x)\n",
    "x = conv4_layer(x)\n",
    "x = conv5_layer(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output_tensor = Dense(K, activation='softmax')(x)  # dense\n",
    "resnet50 = Model(input_tensor, output_tensor)\n",
    "resnet50.summary()\n",
    "\n",
    "resnet50.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "84/84 [==============================] - 103s 994ms/step - loss: 2.7285 - accuracy: 0.2283 - val_loss: 2.4087 - val_accuracy: 0.2005\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 64s 750ms/step - loss: 1.1532 - accuracy: 0.5959 - val_loss: 9.2917 - val_accuracy: 0.1480\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 64s 746ms/step - loss: 0.6257 - accuracy: 0.7830 - val_loss: 2.4826 - val_accuracy: 0.5044\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 64s 748ms/step - loss: 0.4527 - accuracy: 0.8529 - val_loss: 14.9423 - val_accuracy: 0.1620\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 64s 746ms/step - loss: 0.2701 - accuracy: 0.9081 - val_loss: 7.3444 - val_accuracy: 0.3958\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 64s 746ms/step - loss: 0.1991 - accuracy: 0.9330 - val_loss: 6.7340 - val_accuracy: 0.4299\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 0.0941 - accuracy: 0.9642 - val_loss: 0.3217 - val_accuracy: 0.8967\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 64s 747ms/step - loss: 0.1303 - accuracy: 0.9588 - val_loss: 0.4360 - val_accuracy: 0.8827\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 64s 746ms/step - loss: 0.1175 - accuracy: 0.9696 - val_loss: 0.6340 - val_accuracy: 0.8494\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 64s 746ms/step - loss: 0.0546 - accuracy: 0.9800 - val_loss: 0.1790 - val_accuracy: 0.9396\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 64s 749ms/step - loss: 0.1418 - accuracy: 0.9634 - val_loss: 0.1824 - val_accuracy: 0.9518\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 0.1167 - accuracy: 0.9588 - val_loss: 0.4450 - val_accuracy: 0.8818\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 63s 740ms/step - loss: 0.0414 - accuracy: 0.9855 - val_loss: 0.1216 - val_accuracy: 0.9632\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 0.0408 - accuracy: 0.9855 - val_loss: 0.7661 - val_accuracy: 0.8205\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 64s 748ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.0420 - val_accuracy: 0.9851\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 63s 739ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0776 - val_accuracy: 0.9676\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 63s 742ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.1899 - val_accuracy: 0.9527\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.5073 - val_accuracy: 0.8485\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 0.1040 - accuracy: 0.9685 - val_loss: 4.7651 - val_accuracy: 0.5035\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 0.0829 - accuracy: 0.9761 - val_loss: 0.4999 - val_accuracy: 0.8651\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 0.0653 - accuracy: 0.9769 - val_loss: 0.0681 - val_accuracy: 0.9772\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 0.0199 - accuracy: 0.9946 - val_loss: 58.5018 - val_accuracy: 0.2329\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 0.1004 - accuracy: 0.9626 - val_loss: 5.6904 - val_accuracy: 0.5018\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 0.1141 - accuracy: 0.9604 - val_loss: 0.5159 - val_accuracy: 0.8722\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.0710 - val_accuracy: 0.9781\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 0.0283 - accuracy: 0.9934 - val_loss: 0.0348 - val_accuracy: 0.9869\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.2397 - val_accuracy: 0.9238\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 63s 742ms/step - loss: 0.0128 - accuracy: 0.9950 - val_loss: 0.0609 - val_accuracy: 0.9764\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 63s 740ms/step - loss: 0.1538 - accuracy: 0.9524 - val_loss: 0.8085 - val_accuracy: 0.8354\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 0.0274 - accuracy: 0.9885 - val_loss: 0.0717 - val_accuracy: 0.9746\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 63s 744ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0414 - val_accuracy: 0.9851\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 64s 752ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0154 - val_accuracy: 0.9947\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 63s 746ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.2818 - val_accuracy: 0.9194\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 63s 744ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0325 - val_accuracy: 0.9912\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 64s 748ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0898 - val_accuracy: 0.9729\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 63s 739ms/step - loss: 0.0887 - accuracy: 0.9726 - val_loss: 0.8529 - val_accuracy: 0.8214\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 63s 739ms/step - loss: 0.0663 - accuracy: 0.9756 - val_loss: 14.3616 - val_accuracy: 0.4921\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 63s 739ms/step - loss: 0.0508 - accuracy: 0.9836 - val_loss: 0.4991 - val_accuracy: 0.8783\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 0.0822 - accuracy: 0.9765 - val_loss: 0.7352 - val_accuracy: 0.8511\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 63s 744ms/step - loss: 0.0760 - accuracy: 0.9754 - val_loss: 0.4906 - val_accuracy: 0.8757\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 63s 742ms/step - loss: 0.0579 - accuracy: 0.9848 - val_loss: 0.0994 - val_accuracy: 0.9650\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 0.0588 - accuracy: 0.9809 - val_loss: 1.4472 - val_accuracy: 0.8152\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 63s 739ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0407 - val_accuracy: 0.9895\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 9.8294e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9939\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 5.4307e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9939\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 3.5287e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9947\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 64s 747ms/step - loss: 1.7344e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 64s 755ms/step - loss: 7.3081e-05 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9974\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 1.2666e-04 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9974\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 63s 740ms/step - loss: 7.0556e-05 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9974\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 64s 747ms/step - loss: 5.4868e-05 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9974\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 64s 749ms/step - loss: 7.7668e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9965\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 103s 1s/step - loss: 0.2716 - accuracy: 0.9327 - val_loss: 9.0602 - val_accuracy: 0.3275\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 64s 748ms/step - loss: 0.0914 - accuracy: 0.9733 - val_loss: 0.6322 - val_accuracy: 0.8616\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 63s 744ms/step - loss: 0.0451 - accuracy: 0.9900 - val_loss: 0.1511 - val_accuracy: 0.9527\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 63s 740ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.0333 - val_accuracy: 0.9869\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.0399 - val_accuracy: 0.9860\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 64s 755ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.1855 - val_accuracy: 0.9510\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 64s 747ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.3676 - val_accuracy: 0.9002\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.5355 - val_accuracy: 0.8651\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 0.0105 - accuracy: 0.9960 - val_loss: 1.8691 - val_accuracy: 0.6637\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 63s 742ms/step - loss: 0.0807 - accuracy: 0.9767 - val_loss: 0.5004 - val_accuracy: 0.8695\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 0.1670 - val_accuracy: 0.9510\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 64s 752ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 3.1968 - val_accuracy: 0.6357\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 63s 742ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 6.2542 - val_accuracy: 0.5096\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0349 - val_accuracy: 0.9895\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 64s 747ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9947\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 64s 747ms/step - loss: 9.6007e-04 - accuracy: 0.9996 - val_loss: 0.0518 - val_accuracy: 0.9851\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 64s 750ms/step - loss: 2.8874e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9956\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 64s 751ms/step - loss: 5.3496e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9965\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 64s 749ms/step - loss: 2.2718e-04 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9965\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 64s 748ms/step - loss: 1.9887e-04 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9974\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 9.1273e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9974\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 8.2947e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9974\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 1.0016e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9974\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 63s 746ms/step - loss: 1.0011e-04 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9974\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 63s 746ms/step - loss: 4.5412e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9974\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 5.3486e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9974\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 3.7730e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9974\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 63s 739ms/step - loss: 3.3860e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9974\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 63s 740ms/step - loss: 4.3420e-05 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9974\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 2.7727e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 2.9345e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9974\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 2.6752e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 3.0292e-04 - accuracy: 1.0000 - val_loss: 2.2808 - val_accuracy: 0.7058\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 0.4841 - accuracy: 0.9004 - val_loss: 340.6469 - val_accuracy: 0.1331\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 64s 746ms/step - loss: 0.1235 - accuracy: 0.9578 - val_loss: 1.2083 - val_accuracy: 0.7907\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 63s 744ms/step - loss: 0.0219 - accuracy: 0.9913 - val_loss: 0.0596 - val_accuracy: 0.9834\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 63s 739ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.0226 - val_accuracy: 0.9947\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 64s 747ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0197 - val_accuracy: 0.9930\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 0.0073 - accuracy: 0.9950 - val_loss: 0.0206 - val_accuracy: 0.9886\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 63s 742ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9912\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 63s 746ms/step - loss: 5.1672e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9939\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 3.3294e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9939\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 2.0243e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9939\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 63s 743ms/step - loss: 3.0526e-04 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9956\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0277 - val_accuracy: 0.9895\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 63s 741ms/step - loss: 6.6218e-04 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9912\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 64s 751ms/step - loss: 0.0773 - accuracy: 0.9812 - val_loss: 3.5516 - val_accuracy: 0.6208\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 63s 742ms/step - loss: 0.1402 - accuracy: 0.9528 - val_loss: 0.9392 - val_accuracy: 0.8126\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = resnet50.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/##kpu_capstone_voice_data/##model/resnet50_model_9_07(denoise(o), augment(o), bad, batch=32,size=(260x200),origin_spec(0.3)-epoch=130)mk3-2.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "# 기존\n",
    "from keras.models import load_model\n",
    "test = load_model('E:/##kpu_capstone_voice_data/##model/resnet50_model_9_06(denoise(o), augment(o), bad, batch=32,size=(260x200),origin_spec(0.3)-epoch=130).h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변경사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_format='tf' 로 저장\n",
    "from keras.models import load_model\n",
    "resnet50.save('E:/##kpu_capstone_voice_data/##model/resnet50_model_9_07(denoise(o), augment(o), bad, batch=32,size=(260x200),origin_spec(0.3)-epoch=130)mk3-2', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf model 로 load\n",
    "from keras.models import load_model\n",
    "test_model = load_model('E:/##kpu_capstone_voice_data/##model/resnet50_model_9_07(denoise(o), augment(o), bad, batch=32,size=(260x200),origin_spec(0.3)-epoch=130)mk4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "85/85 [==============================] - 99s 865ms/step - loss: nan - accuracy: 0.1515 - val_loss: nan - val_accuracy: 0.1386\n",
      "Epoch 2/5\n",
      "85/85 [==============================] - 49s 574ms/step - loss: nan - accuracy: 0.1426 - val_loss: nan - val_accuracy: 0.1386\n",
      "Epoch 3/5\n",
      "85/85 [==============================] - 49s 578ms/step - loss: nan - accuracy: 0.1426 - val_loss: nan - val_accuracy: 0.1386\n",
      "Epoch 4/5\n",
      "85/85 [==============================] - 49s 577ms/step - loss: nan - accuracy: 0.1426 - val_loss: nan - val_accuracy: 0.1386\n",
      "Epoch 5/5\n",
      "85/85 [==============================] - 49s 577ms/step - loss: nan - accuracy: 0.1426 - val_loss: nan - val_accuracy: 0.1386\n"
     ]
    }
   ],
   "source": [
    "# 이어학습\n",
    "EPOCHS = 5\n",
    "with tf.device('/GPU:0'):\n",
    "    history = test_model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/##kpu_capstone_voice_data/##model/resnet50_model_9_07(denoise(o), augment(o), bad, batch=32,size=(260x200),origin_spec(0.3)-epoch=130)mk4\\assets\n"
     ]
    }
   ],
   "source": [
    "# 저장\n",
    "test_model.save('E:/##kpu_capstone_voice_data/##model/resnet50_model_9_07(denoise(o), augment(o), bad, batch=32,size=(260x200),origin_spec(0.3)-epoch=130)mk4', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 200\n",
    "img_width = 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0540477e-08 9.9999893e-01 1.5703183e-10 3.2211886e-07 1.0118249e-08\n",
      "  4.1645634e-08 6.3862365e-07]]\n",
      "tf.Tensor(\n",
      "[0.11470153 0.31179073 0.11470153 0.11470156 0.11470153 0.11470153\n",
      " 0.11470161], shape=(7,), dtype=float32)\n",
      "새로운 데이터는  클래스일 확률이 31.18%입니다..\n"
     ]
    }
   ],
   "source": [
    "# 모델 체크\n",
    "from keras.preprocessing import image\n",
    "image_path = \"E:/##kpu_capstone_voice_data/##same_amount_voice/#augment_bad_o(per_560)_validation/good_morning/denoisedgood_morning (1).png2.png\"\n",
    "img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "#print(img_array)\n",
    "predictions = test.predict(img_array)\n",
    "print(predictions)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(score)\n",
    "print(\"새로운 데이터는  클래스일 확률이 {:.2f}%입니다..\".format( 100 * np.max(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로운 클래스 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구조 변경\n",
    "\n",
    "### test.layers.pop()  # dense 레이어 삭제 --> 안 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.04466043,  0.06946582, -0.08502575, ..., -0.10097951,\n",
      "        -0.02636709,  0.04760658],\n",
      "       [ 0.03575062,  0.04620038, -0.04354549, ..., -0.15197016,\n",
      "         0.09539365,  0.00958034],\n",
      "       [-0.02776275,  0.00696695,  0.06661399, ..., -0.00194581,\n",
      "        -0.06024632, -0.01319455],\n",
      "       ...,\n",
      "       [-0.00145594,  0.05222666, -0.00341785, ..., -0.06290363,\n",
      "        -0.02085103, -0.03717859],\n",
      "       [-0.0664552 ,  0.02215029, -0.02771749, ...,  0.01322677,\n",
      "        -0.0533746 ,  0.0528442 ],\n",
      "       [ 0.02751628, -0.12613268, -0.01807615, ..., -0.02604857,\n",
      "         0.00124519,  0.08939798]], dtype=float32), array([-0.00420483,  0.02200897, -0.00564838,  0.00252645, -0.00521261,\n",
      "       -0.00827783, -0.00827766], dtype=float32)]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# 모델명: test, weights_bak: 기존 weight 얻기, nb_classes: 기존 class 얻기\n",
    "\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# 기존 모델 weight backup\n",
    "weights_bak = test_model.layers[-1].get_weights()\n",
    "print(weights_bak)\n",
    "nb_classes = test_model.layers[-1].output_shape[-1]\n",
    "print(nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 200, 260, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 206, 266, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 100, 130, 64) 9472        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 100, 130, 64) 256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 100, 130, 64) 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 102, 132, 64) 0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 50, 65, 64)   0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 50, 65, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 50, 65, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 50, 65, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 50, 65, 64)   36928       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 50, 65, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 50, 65, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 50, 65, 256)  16640       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 50, 65, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 50, 65, 256)  1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 50, 65, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 50, 65, 256)  0           batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 50, 65, 256)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 50, 65, 64)   16448       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 50, 65, 64)   256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 50, 65, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 50, 65, 64)   36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 50, 65, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 50, 65, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 50, 65, 256)  16640       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 50, 65, 256)  1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 50, 65, 256)  0           batch_normalization_60[0][0]     \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 50, 65, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 50, 65, 64)   16448       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 50, 65, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 50, 65, 64)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 50, 65, 64)   36928       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 50, 65, 64)   256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 50, 65, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 50, 65, 256)  16640       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 50, 65, 256)  1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 50, 65, 256)  0           batch_normalization_63[0][0]     \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 50, 65, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 25, 33, 128)  32896       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 25, 33, 128)  512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 25, 33, 128)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 25, 33, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 25, 33, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 25, 33, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 25, 33, 512)  66048       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 25, 33, 512)  131584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 25, 33, 512)  2048        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 25, 33, 512)  2048        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 25, 33, 512)  0           batch_normalization_66[0][0]     \n",
      "                                                                 batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 25, 33, 512)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 25, 33, 128)  65664       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 25, 33, 128)  512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 25, 33, 128)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 25, 33, 128)  147584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 25, 33, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 25, 33, 128)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 25, 33, 512)  66048       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 25, 33, 512)  2048        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 25, 33, 512)  0           batch_normalization_70[0][0]     \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 25, 33, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 25, 33, 128)  65664       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 25, 33, 128)  512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 25, 33, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 25, 33, 128)  147584      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 25, 33, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 25, 33, 128)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 25, 33, 512)  66048       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 25, 33, 512)  2048        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 25, 33, 512)  0           batch_normalization_73[0][0]     \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 25, 33, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 25, 33, 128)  65664       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 25, 33, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 25, 33, 128)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 25, 33, 128)  147584      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 25, 33, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 25, 33, 128)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 25, 33, 512)  66048       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 25, 33, 512)  2048        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 25, 33, 512)  0           batch_normalization_76[0][0]     \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 25, 33, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 13, 17, 256)  131328      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 13, 17, 256)  1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 13, 17, 256)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 13, 17, 256)  590080      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 13, 17, 256)  1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 13, 17, 256)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 13, 17, 1024) 263168      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 13, 17, 1024) 525312      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 13, 17, 1024) 4096        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 13, 17, 1024) 4096        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_79[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 13, 17, 1024) 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 13, 17, 256)  262400      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 13, 17, 256)  1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 13, 17, 256)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 13, 17, 256)  590080      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 13, 17, 256)  1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 13, 17, 256)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 13, 17, 1024) 263168      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 13, 17, 1024) 4096        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_83[0][0]     \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 13, 17, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 13, 17, 256)  262400      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 13, 17, 256)  1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 13, 17, 256)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 13, 17, 256)  590080      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 13, 17, 256)  1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 13, 17, 256)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 13, 17, 1024) 263168      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 13, 17, 1024) 4096        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_86[0][0]     \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 13, 17, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 13, 17, 256)  262400      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 13, 17, 256)  1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 13, 17, 256)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 13, 17, 256)  590080      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 13, 17, 256)  1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 13, 17, 256)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 13, 17, 1024) 263168      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 13, 17, 1024) 4096        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_89[0][0]     \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 13, 17, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 13, 17, 256)  262400      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 13, 17, 256)  1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 13, 17, 256)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 13, 17, 256)  590080      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 13, 17, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 13, 17, 256)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 13, 17, 1024) 263168      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 13, 17, 1024) 4096        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_92[0][0]     \n",
      "                                                                 activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 13, 17, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 13, 17, 256)  262400      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 13, 17, 256)  1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 13, 17, 256)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 13, 17, 256)  590080      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 13, 17, 256)  1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_87 (Activation)      (None, 13, 17, 256)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 13, 17, 1024) 263168      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 13, 17, 1024) 4096        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_95[0][0]     \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 13, 17, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 7, 9, 512)    524800      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 7, 9, 512)    2048        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 7, 9, 512)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 9, 512)    2359808     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 7, 9, 512)    2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 9, 512)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 9, 2048)   1050624     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 9, 2048)   2099200     activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 7, 9, 2048)   8192        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 7, 9, 2048)   8192        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_98[0][0]     \n",
      "                                                                 batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 9, 2048)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 9, 512)    1049088     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 7, 9, 512)    2048        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 9, 512)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 9, 512)    2359808     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 7, 9, 512)    2048        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 9, 512)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 9, 2048)   1050624     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 7, 9, 2048)   8192        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_102[0][0]    \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 9, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 9, 512)    1049088     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 7, 9, 512)    2048        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 9, 512)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 9, 512)    2359808     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 9, 512)    2048        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 9, 512)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 9, 2048)   1050624     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 9, 2048)   8192        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_105[0][0]    \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 9, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            14343       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,602,055\n",
      "Trainable params: 23,548,935\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 200, 260, 3), dtype=tf.float32, name='input'), name='input', description=\"created by layer 'input'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 7), dtype=tf.float32, name=None), name='dense_1/Softmax:0', description=\"created by layer 'dense_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2048), dtype=tf.float32, name=None), name='global_average_pooling2d_1/Mean:0', description=\"created by layer 'global_average_pooling2d_1'\")\n"
     ]
    }
   ],
   "source": [
    "test_model.layers.pop()  # dense 레이어 삭제 --> 안 됨\n",
    "\n",
    "# model2= test(inputs=test.input, outputs=test.layers[-2].output)\n",
    "# output_tensor = Dense(K, activation='softmax')(x)\n",
    "print(test_model.input)\n",
    "print(test_model.output)\n",
    "print(test_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x216e6523748>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x216e6522a08>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6525548>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6529548>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e652f248>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x216e652f888>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x216e65328c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6533908>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6537c88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e653af08>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e653ef48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6543508>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6547748>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e654b788>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e654ef88>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6553488>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6559bc8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e655bf08>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6560788>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e65637c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6565c88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e656af08>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e656cf88>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e65724c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6578748>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6577688>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e657ebc8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e6580ec8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6582708>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e65886c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e658cbc8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e658fe48>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e68b4e08>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e68b92c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e68bf4c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e68be548>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e68c7a88>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e68cadc8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e68cb608>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e68d0688>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e68d3b48>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e68d6dc8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e68dbe48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e68e1348>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e68e7608>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e68e9648>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e68ede48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6c04348>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6c0aa48>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e6c0cd48>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6c105c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6c125c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6c16ac8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6c1bd08>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6c1fd08>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6c242c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6c29588>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6c2b608>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6c2db08>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e6c33e48>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6c386c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6c3a6c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6c3dbc8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e00e48>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e02ec8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e09488>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e106c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e0f708>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e15c48>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e6e18f88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e20788>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e21808>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e24d08>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e2c088>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e2cfc8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e32508>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e37788>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e3a7c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e3ccc8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e6e46088>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e46888>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e47908>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e4ae48>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e52108>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e57188>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e5a708>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e5e988>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e5f9c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e68288>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e697c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e6ff08>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e6e762c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e76ac8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e79b48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e83148>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e873c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e88448>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e8c9c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e8ec88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6e90c88>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6e99248>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e6e9e5c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6e9ee08>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6ea1e48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6ea83c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6eac688>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6eaf708>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6eb2c88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6eb5f48>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6eb8fc8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6ebe588>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e6ec58c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6ec7148>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6ecb1c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6ecd708>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6ed27c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6ed3a48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6ed9fc8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6ee32c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6ee5348>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6ee9888>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216e6eecc08>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6eed488>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6ef4508>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216e6ef79c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216e6efac88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216e6efbd08>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216ec4f32c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216ec4f9588>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216ec4fb608>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216ec4feb88>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216ec502f08>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216ec506788>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216ec50a808>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216ec50cd48>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216ec516048>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216ec5170c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216ec51b648>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216ec520908>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216ec51f988>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216ec525f08>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216ec52f2c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216ec52fb08>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216ec571b48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216ec5760c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216ec57c348>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216ec57f388>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216ec583908>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216ec586b88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216ec587c08>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216ec58f508>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216ec592a48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216ec59d1c8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216ec5a2548>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216ec5a2d88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216ec5a4e08>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216ec5aa388>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216edd90648>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216edd92688>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216edd95b88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216edd98e08>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216edd9de88>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216edda2448>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216edda87c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216eddab048>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216eddad088>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216eddb25c8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216eddb6888>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216eddb8908>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216eddb9e88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216eddc2188>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x216eddc5208>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x216eddc8788>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x216eddcbb08>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x216eddd1388>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x216eddd1e08>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x216eddd6b08>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 총 레이어 확인\n",
    "testx = test.layers\n",
    "testx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 8) dtype=float32 (created by layer 'dense_12')>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dense 층 재생성 확인\n",
    "Dense(nb_classes+1, activation='softmax')(test.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 200, 260, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 206, 266, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 100, 130, 64) 9472        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 100, 130, 64) 256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 100, 130, 64) 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 102, 132, 64) 0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 50, 65, 64)   0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 50, 65, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 50, 65, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 50, 65, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 50, 65, 64)   36928       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 50, 65, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 50, 65, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 50, 65, 256)  16640       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 50, 65, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 50, 65, 256)  1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 50, 65, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 50, 65, 256)  0           batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 50, 65, 256)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 50, 65, 64)   16448       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 50, 65, 64)   256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 50, 65, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 50, 65, 64)   36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 50, 65, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 50, 65, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 50, 65, 256)  16640       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 50, 65, 256)  1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 50, 65, 256)  0           batch_normalization_60[0][0]     \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 50, 65, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 50, 65, 64)   16448       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 50, 65, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 50, 65, 64)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 50, 65, 64)   36928       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 50, 65, 64)   256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 50, 65, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 50, 65, 256)  16640       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 50, 65, 256)  1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 50, 65, 256)  0           batch_normalization_63[0][0]     \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 50, 65, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 25, 33, 128)  32896       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 25, 33, 128)  512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 25, 33, 128)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 25, 33, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 25, 33, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 25, 33, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 25, 33, 512)  66048       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 25, 33, 512)  131584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 25, 33, 512)  2048        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 25, 33, 512)  2048        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 25, 33, 512)  0           batch_normalization_66[0][0]     \n",
      "                                                                 batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 25, 33, 512)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 25, 33, 128)  65664       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 25, 33, 128)  512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 25, 33, 128)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 25, 33, 128)  147584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 25, 33, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 25, 33, 128)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 25, 33, 512)  66048       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 25, 33, 512)  2048        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 25, 33, 512)  0           batch_normalization_70[0][0]     \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 25, 33, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 25, 33, 128)  65664       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 25, 33, 128)  512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 25, 33, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 25, 33, 128)  147584      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 25, 33, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 25, 33, 128)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 25, 33, 512)  66048       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 25, 33, 512)  2048        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 25, 33, 512)  0           batch_normalization_73[0][0]     \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 25, 33, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 25, 33, 128)  65664       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 25, 33, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 25, 33, 128)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 25, 33, 128)  147584      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 25, 33, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 25, 33, 128)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 25, 33, 512)  66048       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 25, 33, 512)  2048        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 25, 33, 512)  0           batch_normalization_76[0][0]     \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 25, 33, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 13, 17, 256)  131328      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 13, 17, 256)  1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 13, 17, 256)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 13, 17, 256)  590080      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 13, 17, 256)  1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 13, 17, 256)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 13, 17, 1024) 263168      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 13, 17, 1024) 525312      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 13, 17, 1024) 4096        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 13, 17, 1024) 4096        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_79[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 13, 17, 1024) 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 13, 17, 256)  262400      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 13, 17, 256)  1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 13, 17, 256)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 13, 17, 256)  590080      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 13, 17, 256)  1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 13, 17, 256)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 13, 17, 1024) 263168      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 13, 17, 1024) 4096        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_83[0][0]     \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 13, 17, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 13, 17, 256)  262400      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 13, 17, 256)  1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 13, 17, 256)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 13, 17, 256)  590080      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 13, 17, 256)  1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 13, 17, 256)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 13, 17, 1024) 263168      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 13, 17, 1024) 4096        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_86[0][0]     \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 13, 17, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 13, 17, 256)  262400      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 13, 17, 256)  1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 13, 17, 256)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 13, 17, 256)  590080      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 13, 17, 256)  1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 13, 17, 256)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 13, 17, 1024) 263168      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 13, 17, 1024) 4096        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_89[0][0]     \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 13, 17, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 13, 17, 256)  262400      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 13, 17, 256)  1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 13, 17, 256)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 13, 17, 256)  590080      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 13, 17, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 13, 17, 256)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 13, 17, 1024) 263168      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 13, 17, 1024) 4096        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_92[0][0]     \n",
      "                                                                 activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 13, 17, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 13, 17, 256)  262400      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 13, 17, 256)  1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 13, 17, 256)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 13, 17, 256)  590080      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 13, 17, 256)  1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 13, 17, 256)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 13, 17, 1024) 263168      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 13, 17, 1024) 4096        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_95[0][0]     \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 13, 17, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 7, 9, 512)    524800      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 7, 9, 512)    2048        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 7, 9, 512)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 9, 512)    2359808     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 7, 9, 512)    2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 9, 512)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 9, 2048)   1050624     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 9, 2048)   2099200     activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 7, 9, 2048)   8192        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 7, 9, 2048)   8192        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_98[0][0]     \n",
      "                                                                 batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 9, 2048)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 9, 512)    1049088     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 7, 9, 512)    2048        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 9, 512)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 9, 512)    2359808     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 7, 9, 512)    2048        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 9, 512)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 9, 2048)   1050624     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 7, 9, 2048)   8192        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_102[0][0]    \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 9, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 9, 512)    1049088     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 7, 9, 512)    2048        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 9, 512)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 9, 512)    2359808     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 9, 512)    2048        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 9, 512)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 9, 2048)   1050624     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 9, 2048)   8192        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_105[0][0]    \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 9, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_97[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 200, 260, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 206, 266, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 100, 130, 64) 9472        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 100, 130, 64) 256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 100, 130, 64) 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 102, 132, 64) 0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 50, 65, 64)   0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 50, 65, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 50, 65, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 50, 65, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 50, 65, 64)   36928       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 50, 65, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 50, 65, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 50, 65, 256)  16640       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 50, 65, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 50, 65, 256)  1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 50, 65, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 50, 65, 256)  0           batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 50, 65, 256)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 50, 65, 64)   16448       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 50, 65, 64)   256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 50, 65, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 50, 65, 64)   36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 50, 65, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 50, 65, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 50, 65, 256)  16640       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 50, 65, 256)  1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 50, 65, 256)  0           batch_normalization_60[0][0]     \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 50, 65, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 50, 65, 64)   16448       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 50, 65, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 50, 65, 64)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 50, 65, 64)   36928       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 50, 65, 64)   256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 50, 65, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 50, 65, 256)  16640       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 50, 65, 256)  1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 50, 65, 256)  0           batch_normalization_63[0][0]     \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 50, 65, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 25, 33, 128)  32896       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 25, 33, 128)  512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 25, 33, 128)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 25, 33, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 25, 33, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 25, 33, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 25, 33, 512)  66048       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 25, 33, 512)  131584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 25, 33, 512)  2048        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 25, 33, 512)  2048        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 25, 33, 512)  0           batch_normalization_66[0][0]     \n",
      "                                                                 batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 25, 33, 512)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 25, 33, 128)  65664       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 25, 33, 128)  512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 25, 33, 128)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 25, 33, 128)  147584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 25, 33, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 25, 33, 128)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 25, 33, 512)  66048       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 25, 33, 512)  2048        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 25, 33, 512)  0           batch_normalization_70[0][0]     \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 25, 33, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 25, 33, 128)  65664       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 25, 33, 128)  512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 25, 33, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 25, 33, 128)  147584      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 25, 33, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 25, 33, 128)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 25, 33, 512)  66048       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 25, 33, 512)  2048        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 25, 33, 512)  0           batch_normalization_73[0][0]     \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 25, 33, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 25, 33, 128)  65664       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 25, 33, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 25, 33, 128)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 25, 33, 128)  147584      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 25, 33, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 25, 33, 128)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 25, 33, 512)  66048       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 25, 33, 512)  2048        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 25, 33, 512)  0           batch_normalization_76[0][0]     \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 25, 33, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 13, 17, 256)  131328      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 13, 17, 256)  1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 13, 17, 256)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 13, 17, 256)  590080      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 13, 17, 256)  1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 13, 17, 256)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 13, 17, 1024) 263168      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 13, 17, 1024) 525312      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 13, 17, 1024) 4096        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 13, 17, 1024) 4096        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_79[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 13, 17, 1024) 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 13, 17, 256)  262400      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 13, 17, 256)  1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 13, 17, 256)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 13, 17, 256)  590080      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 13, 17, 256)  1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 13, 17, 256)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 13, 17, 1024) 263168      activation_75[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 13, 17, 1024) 4096        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_83[0][0]     \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 13, 17, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 13, 17, 256)  262400      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 13, 17, 256)  1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 13, 17, 256)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 13, 17, 256)  590080      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 13, 17, 256)  1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 13, 17, 256)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 13, 17, 1024) 263168      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 13, 17, 1024) 4096        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_86[0][0]     \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 13, 17, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 13, 17, 256)  262400      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 13, 17, 256)  1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 13, 17, 256)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 13, 17, 256)  590080      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 13, 17, 256)  1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 13, 17, 256)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 13, 17, 1024) 263168      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 13, 17, 1024) 4096        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_89[0][0]     \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 13, 17, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 13, 17, 256)  262400      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 13, 17, 256)  1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 13, 17, 256)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 13, 17, 256)  590080      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 13, 17, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 13, 17, 256)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 13, 17, 1024) 263168      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 13, 17, 1024) 4096        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_92[0][0]     \n",
      "                                                                 activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 13, 17, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 13, 17, 256)  262400      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 13, 17, 256)  1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 13, 17, 256)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 13, 17, 256)  590080      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 13, 17, 256)  1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 13, 17, 256)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 13, 17, 1024) 263168      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 13, 17, 1024) 4096        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 13, 17, 1024) 0           batch_normalization_95[0][0]     \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 13, 17, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 7, 9, 512)    524800      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 7, 9, 512)    2048        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 7, 9, 512)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 9, 512)    2359808     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 7, 9, 512)    2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 9, 512)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 9, 2048)   1050624     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 9, 2048)   2099200     activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 7, 9, 2048)   8192        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 7, 9, 2048)   8192        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_98[0][0]     \n",
      "                                                                 batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 9, 2048)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 9, 512)    1049088     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 7, 9, 512)    2048        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 9, 512)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 9, 512)    2359808     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 7, 9, 512)    2048        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 9, 512)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 9, 2048)   1050624     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 7, 9, 2048)   8192        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_102[0][0]    \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 9, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 9, 512)    1049088     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 7, 9, 512)    2048        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 9, 512)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 9, 512)    2359808     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 9, 512)    2048        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 9, 512)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 9, 2048)   1050624     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 9, 2048)   8192        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 9, 2048)   0           batch_normalization_105[0][0]    \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 9, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            16392       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,604,104\n",
      "Trainable params: 23,550,984\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# pop dense layer\n",
    "model2 = Model(inputs=test_model.input, outputs=test_model.layers[-2].output)\n",
    "model2.summary()\n",
    "\n",
    "# print(model2.input)\n",
    "\n",
    "# push dense layer\n",
    "model3 = Model(inputs=model2.input, outputs=Dense(num_classes, activation='softmax')(test_model.layers[-2].output))\n",
    "model3.summary()\n",
    "\n",
    "# model2 = Model(inputs=model2.input, outputs=Dense(num_classes, activation='softmax').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.04466043,  0.06946582, -0.08502575, ..., -0.10097951,\n",
      "        -0.02636709,  0.04760658],\n",
      "       [ 0.03575062,  0.04620038, -0.04354549, ..., -0.15197016,\n",
      "         0.09539365,  0.00958034],\n",
      "       [-0.02776275,  0.00696695,  0.06661399, ..., -0.00194581,\n",
      "        -0.06024632, -0.01319455],\n",
      "       ...,\n",
      "       [-0.00145594,  0.05222666, -0.00341785, ..., -0.06290363,\n",
      "        -0.02085103, -0.03717859],\n",
      "       [-0.0664552 ,  0.02215029, -0.02771749, ...,  0.01322677,\n",
      "        -0.0533746 ,  0.0528442 ],\n",
      "       [ 0.02751628, -0.12613268, -0.01807615, ..., -0.02604857,\n",
      "         0.00124519,  0.08939798]], dtype=float32), array([-0.00420483,  0.02200897, -0.00564838,  0.00252645, -0.00521261,\n",
      "       -0.00827783, -0.00827766], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.04466043,  0.06946582, -0.08502575, ..., -0.02636709,\n",
       "          0.04760658, -0.01142132],\n",
       "        [ 0.03575062,  0.04620038, -0.04354549, ...,  0.09539365,\n",
       "          0.00958034, -0.00042271],\n",
       "        [-0.02776275,  0.00696695,  0.06661399, ..., -0.06024632,\n",
       "         -0.01319455, -0.00639524],\n",
       "        ...,\n",
       "        [-0.00145594,  0.05222666, -0.00341785, ..., -0.02085103,\n",
       "         -0.03717859, -0.00961926],\n",
       "        [-0.0664552 ,  0.02215029, -0.02771749, ..., -0.0533746 ,\n",
       "          0.0528442 , -0.01228867],\n",
       "        [ 0.02751628, -0.12613268, -0.01807615, ...,  0.00124519,\n",
       "          0.08939798, -0.01069544]], dtype=float32),\n",
       " array([-0.00420483,  0.02200897, -0.00564838,  0.00252645, -0.00521261,\n",
       "        -0.00827783, -0.00827766, -0.00101227], dtype=float32)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 모델 weight 체크\n",
    "print(weights_bak)\n",
    "# 새로운 모델 weight 저장\n",
    "weights_new = model3.layers[-1].get_weights()\n",
    "weights_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_new[0][:, :-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_bak[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04466043  0.06946582 -0.08502575 ... -0.10097951 -0.02636709\n",
      "   0.04760658]\n",
      " [ 0.03575062  0.04620038 -0.04354549 ... -0.15197016  0.09539365\n",
      "   0.00958034]\n",
      " [-0.02776275  0.00696695  0.06661399 ... -0.00194581 -0.06024632\n",
      "  -0.01319455]\n",
      " ...\n",
      " [-0.00145594  0.05222666 -0.00341785 ... -0.06290363 -0.02085103\n",
      "  -0.03717859]\n",
      " [-0.0664552   0.02215029 -0.02771749 ...  0.01322677 -0.0533746\n",
      "   0.0528442 ]\n",
      " [ 0.02751628 -0.12613268 -0.01807615 ... -0.02604857  0.00124519\n",
      "   0.08939798]] \n",
      " ===================================================================== \n",
      " [[ 0.04466043  0.06946582 -0.08502575 ... -0.10097951 -0.02636709\n",
      "   0.04760658]\n",
      " [ 0.03575062  0.04620038 -0.04354549 ... -0.15197016  0.09539365\n",
      "   0.00958034]\n",
      " [-0.02776275  0.00696695  0.06661399 ... -0.00194581 -0.06024632\n",
      "  -0.01319455]\n",
      " ...\n",
      " [-0.00145594  0.05222666 -0.00341785 ... -0.06290363 -0.02085103\n",
      "  -0.03717859]\n",
      " [-0.0664552   0.02215029 -0.02771749 ...  0.01322677 -0.0533746\n",
      "   0.0528442 ]\n",
      " [ 0.02751628 -0.12613268 -0.01807615 ... -0.02604857  0.00124519\n",
      "   0.08939798]]\n"
     ]
    }
   ],
   "source": [
    "bound = \"=====================================================================\"\n",
    "weights_new[0][:, :-1] = weights_bak[0]\n",
    "print(\"{} \\n {} \\n {}\".format(weights_new[0][:, :-1], bound, weights_bak[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00420483  0.02200897 -0.00564838  0.00252645 -0.00521261 -0.00827783\n",
      " -0.00827766] \n",
      " ===================================================================== \n",
      " [-0.00420483  0.02200897 -0.00564838  0.00252645 -0.00521261 -0.00827783\n",
      " -0.00827766]\n"
     ]
    }
   ],
   "source": [
    "weights_new[1][:-1] = weights_bak[1]\n",
    "print(\"{} \\n {} \\n {}\".format(weights_new[1][:-1], bound, weights_bak[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_new[0][:, -1] = np.mean(weights_bak[0], axis=1)\n",
    "weights_new[1][-1] = np.mean(weights_bak[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.04466043,  0.06946582, -0.08502575, ..., -0.02636709,\n",
       "          0.04760658, -0.01142132],\n",
       "        [ 0.03575062,  0.04620038, -0.04354549, ...,  0.09539365,\n",
       "          0.00958034, -0.00042271],\n",
       "        [-0.02776275,  0.00696695,  0.06661399, ..., -0.06024632,\n",
       "         -0.01319455, -0.00639524],\n",
       "        ...,\n",
       "        [-0.00145594,  0.05222666, -0.00341785, ..., -0.02085103,\n",
       "         -0.03717859, -0.00961926],\n",
       "        [-0.0664552 ,  0.02215029, -0.02771749, ..., -0.0533746 ,\n",
       "          0.0528442 , -0.01228867],\n",
       "        [ 0.02751628, -0.12613268, -0.01807615, ...,  0.00124519,\n",
       "          0.08939798, -0.01069544]], dtype=float32),\n",
       " array([-0.00420483,  0.02200897, -0.00564838,  0.00252645, -0.00521261,\n",
       "        -0.00827783, -0.00827766, -0.00101227], dtype=float32)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.layers[-1].set_weights(weights_new)\n",
    "model3.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "85/85 [==============================] - 98s 899ms/step - loss: 0.7852 - accuracy: 0.9279 - val_loss: 0.1175 - val_accuracy: 0.9610\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 50s 592ms/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 0.0768 - val_accuracy: 0.9783\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 50s 591ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9948\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 50s 592ms/step - loss: 8.8812e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9957\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 50s 592ms/step - loss: 6.6020e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9965\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 50s 590ms/step - loss: 4.3420e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9965\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 50s 589ms/step - loss: 3.3970e-04 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9965\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 51s 600ms/step - loss: 2.9929e-04 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9965\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 50s 592ms/step - loss: 2.3025e-04 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9965\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 51s 601ms/step - loss: 2.0433e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9965\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model3.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/##kpu_capstone_voice_data/##model/resnet50_model_9_07(denoise(o), augment(o), bad, addclass, batch=32,size=(260x200),origin_spec(0.3)-epoch=130)mk5\\assets\n"
     ]
    }
   ],
   "source": [
    "# 저장\n",
    "model3.save('E:/##kpu_capstone_voice_data/##model/resnet50_model_9_07(denoise(o), augment(o), bad, addclass, batch=32,size=(260x200),origin_spec(0.3)-epoch=130)mk5', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_model('E:/##kpu_capstone_voice_data/##model/resnet50_model_9_07(denoise(o), augment(o), bad, addclass, batch=32,size=(260x200),origin_spec(0.3)-epoch=130)mk5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:/##kpu_capstone_voice_data/##same_amount_voice/#augment_bad_o(per_560)_validation/yotube_dongbinna/mung_dongbinna (1).png_denoised.png1_augment.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-ac77e51522bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"E:/##kpu_capstone_voice_data/##same_amount_voice/#augment_bad_o(per_560)_validation/yotube_dongbinna/mung_dongbinna (1).png_denoised.png1_augment.png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Create a batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\capstone2021\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    298\u001b[0m   \"\"\"\n\u001b[0;32m    299\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[1;32m--> 300\u001b[1;33m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\capstone2021\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/##kpu_capstone_voice_data/##same_amount_voice/#augment_bad_o(per_560)_validation/yotube_dongbinna/mung_dongbinna (1).png_denoised.png1_augment.png'"
     ]
    }
   ],
   "source": [
    "# 모델 체크\n",
    "from keras.preprocessing import image\n",
    "image_path = \"E:\\##kpu_capstone_voice_data/##same_amount_voice/#augment_bad_o(per_560)_validation/youtube_dongbinna/mung_dongbinna (1).png_denoised.png1_augment.png\"\n",
    "img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "#print(img_array)\n",
    "predictions = test.predict(img_array)\n",
    "print(predictions)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(score)\n",
    "print(\"새로운 데이터는 {} 클래스일 확률이 {:.2f}%입니다..\".format(class_names[np.argmax(score)], 100 * np.max(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone2021",
   "language": "python",
   "name": "capstone2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
