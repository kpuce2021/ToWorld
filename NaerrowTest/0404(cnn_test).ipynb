{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249ed376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde5049b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4931377440882276426,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 727437753581721322\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7046801664\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 7905437386767828166\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:1c:00.0, compute capability: 6.1\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 1964922451373810330\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.debugging.set_log_device_placement(True)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b943af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device('/GPU:0'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b511babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # 1번함수\n",
    "# def get_label(file_path):\n",
    "#     # convert the path to a list of path components\n",
    "#     parts = tf.strings.split(file_path, os.path.sep)\n",
    "#     # The second to last is the class-directory\n",
    "#     one_hot = parts[-2] == class_names\n",
    "#     # Integer encode the label\n",
    "#     return tf.argmax(one_hot)\n",
    "# def decode_img(img):\n",
    "#     # convert the compressed string to a 3D uint8 tensor\n",
    "#     img = tf.image.decode_jpeg(img, channels=3)\n",
    "#     # resize the image to the desired size\n",
    "#     return tf.image.resize(img, [img_height, img_width])\n",
    "# def process_path(file_path):\n",
    "#     label = get_label(file_path)\n",
    "#     # load the raw data from the file as a string\n",
    "#     img = tf.io.read_file(file_path)\n",
    "#     img = decode_img(img)\n",
    "#     return img, label\n",
    "# # 2번 함수\n",
    "# def configure_for_performance(ds):\n",
    "#     ds = ds.cache()\n",
    "#     ds = ds.shuffle(buffer_size=1000)\n",
    "#     ds = ds.batch(batch_size)\n",
    "#     ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "#     return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9589101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/voice')\n",
    "#data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/raw_data')\n",
    "#data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/test_image(after)')\n",
    "#data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data')\n",
    "\n",
    "#data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/snow_flo')\n",
    "data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/train_data/denoise_origin_size_data/rm_temp_spec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad1eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# img = cv2.imread('C:/Users/jaehee/.keras/datasets/snow_flo/unnoisedc (1).png')\n",
    "# print(type(img))\n",
    "# print(img.shape)\n",
    "# print(type(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6699fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432, 288)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "#i = Image.open('C:/Users/jaehee/.keras/datasets/snow_flo/unnoisedc (1).png')\n",
    "\n",
    "image1 = Image.open(str(data_dir)+'/traffic/unnoisedc (2).png')\n",
    "\n",
    "#image1.show()\n",
    "\n",
    "image_size = image1.size\n",
    "print(image_size)\n",
    "img_width=image_size[0]\n",
    "img_height=image_size[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c9f745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "source": [
    "data_dir\n",
    "image_count = len(list(data_dir.glob('*/*.png')))\n",
    "print(image_count)\n",
    "# temp = list(data_dir.glob('*/*.png'))\n",
    "# temp[0]\n",
    "#img = cv2.imread('C:/Users/Administrator/Desktop/python/origin/python.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b1b165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 files belonging to 3 classes.\n",
      "Using 525 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "split_percent=0.3\n",
    "# img_height = 122#128\n",
    "# img_width = 187#256\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=split_percent,\n",
    "    subset=\"training\",\n",
    "    #color_mode=\"grayscale\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e83ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 288, 432, 3)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f647fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 files belonging to 3 classes.\n",
      "Using 225 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=split_percent ,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    #color_mode=\"grayscale\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0feab27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import models, layers\n",
    "# from keras import Input\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras import optimizers, initializers, regularizers, metrics\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    " \n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# #data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data')\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# train_dir = os.path.join('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data_resnet/train')\n",
    "# val_dir = os.path.join('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data_resnet/test')\n",
    " \n",
    " \n",
    " \n",
    "# train_generator = train_datagen.flow_from_directory(train_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "# val_generator = val_datagen.flow_from_directory(val_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baf13369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(train_generator))\n",
    "# print(type(train_ds))\n",
    "\n",
    "# print(type(train_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647fa34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5062326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['morning', 'traffic', 'weather']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "num_classes = len(class_names)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adbd01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 288, 432, 3)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b118b351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 288, 432, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    #for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(class_names[labels[i]])\n",
    "#         plt.axis(\"off\")\n",
    "#         print(images.shape)\n",
    "    image_size = images.shape\n",
    "    print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "426435c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (16, 288, 432, 3)\n",
      "Label:  [0 2 1 0 1 1 1 2 2 2 0 1 0 1 1 2]\n",
      "Image shape:  (16, 288, 432, 3)\n",
      "Label:  [0 1 0 0 0 2 0 2 1 1 1 2 0 0 2 1]\n",
      "Image shape:  (16, 288, 432, 3)\n",
      "Label:  [1 2 2 2 0 2 0 0 0 1 0 1 2 1 1 1]\n",
      "Image shape:  (16, 288, 432, 3)\n",
      "Label:  [0 2 0 2 2 0 1 0 2 0 2 1 1 1 2 0]\n",
      "Image shape:  (16, 288, 432, 3)\n",
      "Label:  [1 1 2 1 2 1 1 0 0 1 1 0 2 0 2 0]\n",
      "Image shape:  (16, 288, 432, 3)\n",
      "Label:  [1 1 2 2 2 0 1 0 1 0 0 2 2 2 1 0]\n",
      "Image shape:  (16, 288, 432, 3)\n",
      "Label:  [0 0 0 0 1 2 1 2 2 0 1 2 2 0 0 1]\n",
      "Image shape:  (16, 288, 432, 3)\n",
      "Label:  [0 0 0 0 0 0 1 1 0 0 2 0 2 0 0 1]\n",
      "Image shape:  (16, 288, 432, 3)\n",
      "Label:  [2 2 1 0 0 2 2 1 1 1 2 2 0 1 2 0]\n",
      "Image shape:  (16, 288, 432, 3)\n",
      "Label:  [2 0 0 0 2 0 0 1 2 1 0 1 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(10):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57da6651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 288, 432, 3), (None,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84a91144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위랑 성능 비교해 봐야 함\n",
    "\n",
    "# 1번 함수 사용 \n",
    "# train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "# val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# 2번 함수 사용\n",
    "# train_ds = configure_for_performance(train_ds)\n",
    "# val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc5ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞의 몇 개 데이터 이미지 시각화 시켜서 확인\n",
    "\n",
    "# image_batch, label_batch = next(iter(train_ds))\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#     label = label_batch[i]\n",
    "#     plt.title(class_names[label])\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebfe14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce7fb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.9960785\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "#print(image_batch, labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c729cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "#     layers.Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Dropout(0.2),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(num_classes)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "406036f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########## 여서부터 CNN 시작 ############\n",
    "# model = Sequential() # Sequential 모델은 각 레이어에 정확히 하나의 입력 텐서와 하나의 출력 텐서가 있는 일반 레이어 스택에 적합합니다\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(256,128,1))) # Conv2D: 필터 수, kernal_size: 필터 크기, input_shape= 입력층 (가로: 50, 세로: 50, 채널: 3) 모델에 적용\n",
    "#                                                                                       # zero paddding의 값은? (Filter Size - 1) / 2\n",
    "#                                                                                     # 굳이 알필요는 없지만 출력층의 weight의 개수는? ( Input Size + 2 * Padding - Filter Size ) / Stride + 1 ( 4 + 2 * 0 - 2 ) / 1 + 1 = 3 * 3\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2))) # 사이즈 줄이고-> 여기서 padding을 설정하면 same으로 하면 같이 유지가 돼 가장 네모 정사각형 안겹치게 해서 가장 큰 값 뽑아내기\n",
    "# model.add(Dropout(0.25)) # Dropout란? 과적합을 방지하기 위해서 학습 시에 지정된 비율만큼 임의의 입력 뉴런(1차원)을 제외시킵니다.\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu')) # 첫번째 인자 : 출력 뉴런의 수를 설정합니다, input_dim : 입력 뉴런의 수를 설정합니다\n",
    "#                                          # init : 가중치 초기화 방법 설정합니다.‘uniform’ : 균일 분포, ‘normal’ : 가우시안 분포\n",
    "# # model.add(Dropout(0.5))\n",
    "# model.add(Dense(3, activation='softmax')) # 소프트맥스 출력의 각 원소는 0.0 이상 1.0 이하의 실수입니다. 그리고 노드의 출력을 모두 합한 값이 항상 1이 됩니다.\n",
    "#                                           # 소프트맥스 함수의 좋은 점은 예측이 잘 이루어지면 1에 가까운 출력은 하나만 있고 다른 출력은 0에 가까워진다는 점입니다.\n",
    "#                                           # 하지만 예측이 잘 이루어지지 않으면 여러 레이블이 비슷한 확률을 가지게 될 수 있습니다.\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# history = model.fit_generator(train_generator, steps_per_epoch=200, epochs=50, validation_data=test_generator, validation_steps= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "634ffa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3bc165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c29623a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 288, 432, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 294, 438, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 144, 216, 64) 9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 144, 216, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 144, 216, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 146, 218, 64) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 72, 108, 64)  0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 108, 64)  4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 108, 64)  256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 108, 64)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 108, 64)  36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 108, 64)  256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 108, 64)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 72, 108, 256) 16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 72, 108, 256) 16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 72, 108, 256) 1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 72, 108, 256) 1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 72, 108, 256) 0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 72, 108, 256) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 72, 108, 64)  16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 72, 108, 64)  256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 72, 108, 64)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 72, 108, 64)  36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 72, 108, 64)  256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 72, 108, 64)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 72, 108, 256) 16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 72, 108, 256) 1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 72, 108, 256) 0           batch_normalization_7[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 72, 108, 256) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 72, 108, 64)  16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 72, 108, 64)  256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 72, 108, 64)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 72, 108, 64)  36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 72, 108, 64)  256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 72, 108, 64)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 72, 108, 256) 16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 72, 108, 256) 1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 72, 108, 256) 0           batch_normalization_10[0][0]     \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 72, 108, 256) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 36, 54, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 36, 54, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 36, 54, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 36, 54, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 36, 54, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 36, 54, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 36, 54, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 36, 54, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 36, 54, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 36, 54, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 36, 54, 512)  0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 36, 54, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 36, 54, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 36, 54, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 36, 54, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 36, 54, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 36, 54, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 36, 54, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 36, 54, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 36, 54, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 36, 54, 512)  0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 36, 54, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 36, 54, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 36, 54, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 36, 54, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 36, 54, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 36, 54, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 36, 54, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 36, 54, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 36, 54, 512)  2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 36, 54, 512)  0           batch_normalization_20[0][0]     \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 36, 54, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 36, 54, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 36, 54, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 36, 54, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 36, 54, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 36, 54, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 36, 54, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 36, 54, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 36, 54, 512)  2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 36, 54, 512)  0           batch_normalization_23[0][0]     \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 36, 54, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 18, 27, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 18, 27, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 18, 27, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 18, 27, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 18, 27, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 18, 27, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 18, 27, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 18, 27, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 18, 27, 1024) 4096        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 18, 27, 1024) 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 18, 27, 1024) 0           batch_normalization_26[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 18, 27, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 18, 27, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 18, 27, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 18, 27, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 18, 27, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 18, 27, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 18, 27, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 18, 27, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 18, 27, 1024) 4096        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 18, 27, 1024) 0           batch_normalization_30[0][0]     \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 18, 27, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 18, 27, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 18, 27, 256)  1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 18, 27, 256)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 18, 27, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 18, 27, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 18, 27, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 18, 27, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 18, 27, 1024) 4096        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 18, 27, 1024) 0           batch_normalization_33[0][0]     \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 18, 27, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 18, 27, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 18, 27, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 18, 27, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 18, 27, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 18, 27, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 18, 27, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 18, 27, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 18, 27, 1024) 4096        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 18, 27, 1024) 0           batch_normalization_36[0][0]     \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 18, 27, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 18, 27, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 18, 27, 256)  1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 18, 27, 256)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 18, 27, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 18, 27, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 18, 27, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 18, 27, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 18, 27, 1024) 4096        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 18, 27, 1024) 0           batch_normalization_39[0][0]     \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 18, 27, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 18, 27, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 18, 27, 256)  1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 18, 27, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 18, 27, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 18, 27, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 18, 27, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 18, 27, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 18, 27, 1024) 4096        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 18, 27, 1024) 0           batch_normalization_42[0][0]     \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 18, 27, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 9, 14, 512)   524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 9, 14, 512)   2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 9, 14, 512)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 9, 14, 512)   2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 9, 14, 512)   2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 9, 14, 512)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 9, 14, 2048)  1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 9, 14, 2048)  2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 9, 14, 2048)  8192        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 9, 14, 2048)  8192        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 9, 14, 2048)  0           batch_normalization_45[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 9, 14, 2048)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 9, 14, 512)   1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 9, 14, 512)   2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 9, 14, 512)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 9, 14, 512)   2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 9, 14, 512)   2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 9, 14, 512)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 9, 14, 2048)  1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 9, 14, 2048)  8192        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 9, 14, 2048)  0           batch_normalization_49[0][0]     \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 9, 14, 2048)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 9, 14, 512)   1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 9, 14, 512)   2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 9, 14, 512)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 9, 14, 512)   2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 9, 14, 512)   2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 9, 14, 512)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 9, 14, 2048)  1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 9, 14, 2048)  8192        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 9, 14, 2048)  0           batch_normalization_52[0][0]     \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 9, 14, 2048)  0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            6147        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 23,593,859\n",
      "Trainable params: 23,540,739\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    " \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data')\n",
    "\n",
    "#train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#val_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "#train_dir = os.path.join('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data/train')\n",
    "#val_dir = os.path.join('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data/test')\n",
    " \n",
    " \n",
    " \n",
    "#train_generator = train_datagen.flow_from_directory(train_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "#val_generator = val_datagen.flow_from_directory(val_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "\n",
    "# number of classes\n",
    "#K = 4\n",
    "K = 3\n",
    "#img_height = 122#128\n",
    "#img_width = 187#256\n",
    "input_tensor = Input(shape=(img_height, img_width, 3), dtype='float32', name='input') # shape=(224, 224, 3)\n",
    "\n",
    "def conv1_layer(x):    \n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x)\n",
    " \n",
    "    return x   \n",
    " \n",
    "    \n",
    "def conv2_layer(x):         \n",
    "    x = MaxPooling2D((3, 3), 2)(x)     \n",
    " \n",
    "    shortcut = x\n",
    " \n",
    "    for i in range(3):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)            \n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    " \n",
    "        else:\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])   \n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            shortcut = x        \n",
    "    \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv3_layer(x):        \n",
    "    shortcut = x    \n",
    "    \n",
    "    for i in range(4):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)    \n",
    " \n",
    "            shortcut = x              \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])     \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    "            \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv4_layer(x):\n",
    "    shortcut = x        \n",
    "  \n",
    "    for i in range(6):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv5_layer(x):\n",
    "    shortcut = x    \n",
    "  \n",
    "    for i in range(3):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])  \n",
    "            x = Activation('relu')(x)      \n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)           \n",
    "            \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)       \n",
    " \n",
    "            shortcut = x                  \n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "x = conv1_layer(input_tensor)\n",
    "x = conv2_layer(x)\n",
    "x = conv3_layer(x)\n",
    "x = conv4_layer(x)\n",
    "x = conv5_layer(x)\n",
    " \n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output_tensor = Dense(K, activation='softmax')(x)\n",
    " \n",
    "resnet50 = Model(input_tensor, output_tensor)\n",
    "resnet50.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6b8e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0f4d6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      " 2/33 [>.............................] - ETA: 9s - loss: 0.5813 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1581s vs `on_train_batch_end` time: 0.2384s). Check your callbacks.\n",
      "33/33 [==============================] - 16s 488ms/step - loss: 0.6229 - accuracy: 0.9257 - val_loss: 1.2270 - val_accuracy: 0.3244\n",
      "Epoch 2/130\n",
      "33/33 [==============================] - 15s 441ms/step - loss: 0.6308 - accuracy: 0.9143 - val_loss: 1.2270 - val_accuracy: 0.3244\n",
      "Epoch 3/130\n",
      "33/33 [==============================] - 15s 460ms/step - loss: 0.6222 - accuracy: 0.9276 - val_loss: 1.0154 - val_accuracy: 0.5333\n",
      "Epoch 4/130\n",
      "33/33 [==============================] - 15s 458ms/step - loss: 0.5965 - accuracy: 0.9562 - val_loss: 1.2492 - val_accuracy: 0.3022\n",
      "Epoch 5/130\n",
      "33/33 [==============================] - 15s 449ms/step - loss: 0.5920 - accuracy: 0.9600 - val_loss: 1.2492 - val_accuracy: 0.3022\n",
      "Epoch 6/130\n",
      "33/33 [==============================] - 15s 448ms/step - loss: 0.5850 - accuracy: 0.9657 - val_loss: 1.2448 - val_accuracy: 0.3067\n",
      "Epoch 7/130\n",
      "33/33 [==============================] - 15s 454ms/step - loss: 0.5761 - accuracy: 0.9752 - val_loss: 1.2234 - val_accuracy: 0.3244\n",
      "Epoch 8/130\n",
      "33/33 [==============================] - 15s 453ms/step - loss: 0.5882 - accuracy: 0.9619 - val_loss: 0.9250 - val_accuracy: 0.6267\n",
      "Epoch 9/130\n",
      "33/33 [==============================] - 15s 454ms/step - loss: 0.5816 - accuracy: 0.9733 - val_loss: 0.9302 - val_accuracy: 0.6222\n",
      "Epoch 10/130\n",
      "33/33 [==============================] - 15s 453ms/step - loss: 0.6015 - accuracy: 0.9429 - val_loss: 1.2236 - val_accuracy: 0.3289\n",
      "Epoch 11/130\n",
      "33/33 [==============================] - 15s 449ms/step - loss: 0.5842 - accuracy: 0.9676 - val_loss: 1.2270 - val_accuracy: 0.3244\n",
      "Epoch 12/130\n",
      "33/33 [==============================] - 15s 447ms/step - loss: 0.5763 - accuracy: 0.9752 - val_loss: 0.9032 - val_accuracy: 0.6400\n",
      "Epoch 13/130\n",
      "33/33 [==============================] - 15s 445ms/step - loss: 0.5727 - accuracy: 0.9790 - val_loss: 1.1062 - val_accuracy: 0.4400\n",
      "Epoch 14/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5659 - accuracy: 0.9848 - val_loss: 1.1191 - val_accuracy: 0.4178\n",
      "Epoch 15/130\n",
      "33/33 [==============================] - 15s 446ms/step - loss: 0.5884 - accuracy: 0.9600 - val_loss: 1.2270 - val_accuracy: 0.3244\n",
      "Epoch 16/130\n",
      "33/33 [==============================] - 15s 456ms/step - loss: 0.5742 - accuracy: 0.9771 - val_loss: 1.0998 - val_accuracy: 0.4489\n",
      "Epoch 17/130\n",
      "33/33 [==============================] - 15s 454ms/step - loss: 0.5752 - accuracy: 0.9733 - val_loss: 0.5670 - val_accuracy: 0.9822\n",
      "Epoch 18/130\n",
      "33/33 [==============================] - 15s 446ms/step - loss: 0.5920 - accuracy: 0.9600 - val_loss: 0.7553 - val_accuracy: 0.7911\n",
      "Epoch 19/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5688 - accuracy: 0.9829 - val_loss: 1.2270 - val_accuracy: 0.3244\n",
      "Epoch 20/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.6113 - accuracy: 0.9390 - val_loss: 0.7342 - val_accuracy: 0.8133\n",
      "Epoch 21/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5889 - accuracy: 0.9619 - val_loss: 1.1781 - val_accuracy: 0.3733\n",
      "Epoch 22/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5757 - accuracy: 0.9771 - val_loss: 1.0353 - val_accuracy: 0.5111\n",
      "Epoch 23/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5908 - accuracy: 0.9600 - val_loss: 1.2270 - val_accuracy: 0.3244\n",
      "Epoch 24/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5738 - accuracy: 0.9771 - val_loss: 0.7795 - val_accuracy: 0.7733\n",
      "Epoch 25/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5753 - accuracy: 0.9771 - val_loss: 1.2270 - val_accuracy: 0.3244\n",
      "Epoch 26/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5650 - accuracy: 0.9867 - val_loss: 1.2270 - val_accuracy: 0.3244\n",
      "Epoch 27/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5612 - accuracy: 0.9905 - val_loss: 0.9513 - val_accuracy: 0.6000\n",
      "Epoch 28/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5665 - accuracy: 0.9848 - val_loss: 0.6500 - val_accuracy: 0.9022\n",
      "Epoch 29/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5769 - val_accuracy: 0.9733\n",
      "Epoch 30/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5648 - val_accuracy: 0.9867\n",
      "Epoch 31/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5647 - val_accuracy: 0.9867\n",
      "Epoch 32/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5626 - val_accuracy: 0.9867\n",
      "Epoch 33/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 34/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 35/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 36/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 37/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 38/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 39/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 40/130\n",
      "33/33 [==============================] - 15s 444ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 41/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 42/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 43/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 44/130\n",
      "33/33 [==============================] - 15s 445ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 45/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 46/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 47/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 48/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 49/130\n",
      "33/33 [==============================] - 15s 441ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 50/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 51/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 52/130\n",
      "33/33 [==============================] - 15s 445ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5605 - val_accuracy: 0.9911\n",
      "Epoch 53/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 54/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 55/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/130\n",
      "33/33 [==============================] - 15s 453ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 57/130\n",
      "33/33 [==============================] - 15s 452ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 58/130\n",
      "33/33 [==============================] - 15s 449ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 59/130\n",
      "33/33 [==============================] - 15s 447ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 60/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 61/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 62/130\n",
      "33/33 [==============================] - 15s 441ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 63/130\n",
      "33/33 [==============================] - 15s 441ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 64/130\n",
      "33/33 [==============================] - 15s 447ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 65/130\n",
      "33/33 [==============================] - 15s 446ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 66/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 67/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 68/130\n",
      "33/33 [==============================] - 15s 450ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 69/130\n",
      "33/33 [==============================] - 15s 443ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 70/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 71/130\n",
      "33/33 [==============================] - 15s 442ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 72/130\n",
      "33/33 [==============================] - 15s 445ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 73/130\n",
      "33/33 [==============================] - 15s 445ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 74/130\n",
      "33/33 [==============================] - 14s 427ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 75/130\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 76/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 77/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 78/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 79/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 80/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5606 - val_accuracy: 0.9911\n",
      "Epoch 81/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 82/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 83/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 84/130\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 85/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 86/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 87/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 88/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 89/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 90/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 91/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 92/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 93/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 94/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 95/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 96/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 97/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 98/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 99/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 100/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 101/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 102/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 103/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 104/130\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 105/130\n",
      "33/33 [==============================] - 14s 434ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 106/130\n",
      "33/33 [==============================] - 14s 418ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 107/130\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 108/130\n",
      "33/33 [==============================] - 14s 420ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 109/130\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5607 - val_accuracy: 0.9911\n",
      "Epoch 110/130\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 111/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 112/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 113/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 114/130\n",
      "33/33 [==============================] - 14s 422ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 115/130\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 116/130\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 117/130\n",
      "33/33 [==============================] - 14s 426ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 118/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 119/130\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 120/130\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 121/130\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5611 - val_accuracy: 0.9911\n",
      "Epoch 122/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5610 - val_accuracy: 0.9911\n",
      "Epoch 123/130\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 124/130\n",
      "33/33 [==============================] - 14s 413ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 125/130\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 126/130\n",
      "33/33 [==============================] - 14s 422ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 127/130\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 128/130\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5608 - val_accuracy: 0.9911\n",
      "Epoch 129/130\n",
      "33/33 [==============================] - 14s 414ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n",
      "Epoch 130/130\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.5610 - accuracy: 0.9905 - val_loss: 0.5609 - val_accuracy: 0.9911\n"
     ]
    }
   ],
   "source": [
    "#with tf.device('/GPU:0'):\n",
    "EPOCHS=130\n",
    "history = resnet50.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    #callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45584cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "resnet50.save('model/resnet50_model_6_23(denoise(o),e=16,size=(288x432),origin_spec(0.3)-epoch=130).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f19a9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model/resnet50_model_6_23(denoise(x),e=25,size=(288x432),new_spec(0.3)).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09dc058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_avg = 0.9850\n",
      "test_avg = 0.8823\n"
     ]
    }
   ],
   "source": [
    "train_avg = np.mean(history.history['accuracy'])\n",
    "test_avg = np.mean(history.history['val_accuracy'])\n",
    "print('train_avg = {0:.4f}'.format(train_avg))\n",
    "print('test_avg = {0:.4f}'.format(test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ded2a7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b8818408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model.save('model/voice_predict_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8fad99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # image = cv2.imread('C:\\\\Users\\\\jaehee\\\\Desktop\\\\jupyter_proj\\\\test_voice\\\\tvon.png')\n",
    "# # gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "# # plt.imshow(gray, cmap='gray')\n",
    "# # plt.show()\n",
    "# img = Image.open('C:\\\\Users\\\\jaehee\\\\Desktop\\\\jupyter_proj\\\\test_voice\\\\tvon.png')\n",
    "# imgGray = img.convert('L')\n",
    "# imgGray.save('test_gray.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d32c9ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing import image\n",
    "\n",
    "# image_path = 'C:\\\\Users\\\\jaehee\\\\Desktop\\\\jupyter_proj\\\\test_voice\\\\tvon.png'\n",
    "# img = image.load_img(image_path, target_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47e1c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.031670e-14 2.127867e-21 1.000000e+00]]\n",
      "tf.Tensor([0.21194156 0.21194156 0.57611686], shape=(3,), dtype=float32)\n",
      "새로운 데이터는 weather 클래스일 확률이 57.61%입니다..\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "#C:/Users/jaehee/.keras/datasets/prediction_data/prediction/preprocessed/morning/g3.png\n",
    "#C:/Users/jaehee/.keras/datasets/snow_flo/weather/unnoisedtomorrow_weather (27).png\n",
    "# moring = > C:/Users/jaehee/.keras/datasets/train_data/denoise_origin_size_data/rm_temp_spec/morning/unnoisedg (10).png\n",
    "# traffic => C:/Users/jaehee/.keras/datasets/train_data/denoise_origin_size_data/rm_temp_spec/traffic/unnoisedc (1).png\n",
    "# weather => C:/Users/jaehee/.keras/datasets/train_data/denoise_origin_size_data/rm_temp_spec/weather/unnoisedn (1).png\n",
    "\n",
    "# predict data\n",
    "# morning => C:/Users/jaehee/.keras/datasets/prediction_data/prediction/ingb_prediction (2)/rm_spec/morning/unnoisedg1.png\n",
    "# traffic => C:/Users/jaehee/.keras/datasets/prediction_data/prediction/ingb_prediction (2)/rm_spec/traffic/unnoisedc1.png\n",
    "# weather => C:/Users/jaehee/.keras/datasets/prediction_data/prediction/ingb_prediction (2)/rm_spec/weather/unnoisedn1.png\n",
    "image_path = 'C:/Users/jaehee/.keras/datasets/prediction_data/prediction/ingb_prediction (2)/rm_spec/weather/unnoisedn3.png'\n",
    "img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "#print(img_array)\n",
    "predictions = resnet50.predict(img_array)\n",
    "print(predictions)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(score)\n",
    "print(\"새로운 데이터는 {} 클래스일 확률이 {:.2f}%입니다..\".format(class_names[np.argmax(score)], 100 * np.max(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f40eaba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c6f587e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('voice_predict_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8296b037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_3 (Rescaling)      (None, 128, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 128, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 128, 32)       4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 4,218,403\n",
      "Trainable params: 4,218,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117dcd58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naerrow",
   "language": "python",
   "name": "naerrow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
