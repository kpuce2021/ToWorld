{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249ed376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1번함수\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    one_hot = parts[-2] == class_names\n",
    "    # Integer encode the label\n",
    "    return tf.argmax(one_hot)\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size\n",
    "    return tf.image.resize(img, [img_height, img_width])\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "# 2번 함수\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9589101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/voice')\n",
    "#data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/raw_data')\n",
    "data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72c9f745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "data_dir\n",
    "image_count = len(list(data_dir.glob('*/*.png')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b1b165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 files belonging to 3 classes.\n",
      "Using 1050 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 128\n",
    "img_width = 256\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    #color_mode=\"grayscale\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f647fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 files belonging to 3 classes.\n",
      "Using 450 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    #color_mode=\"grayscale\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2599b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1050 images belonging to 3 classes.\n",
      "Found 450 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# from keras import models, layers\n",
    "# from keras import Input\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras import optimizers, initializers, regularizers, metrics\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    " \n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# #data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data')\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# train_dir = os.path.join('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data_resnet/train')\n",
    "# val_dir = os.path.join('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data_resnet/test')\n",
    " \n",
    " \n",
    " \n",
    "# train_generator = train_datagen.flow_from_directory(train_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "# val_generator = val_datagen.flow_from_directory(val_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4f52808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.preprocessing.image.DirectoryIterator'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# print(type(train_generator))\n",
    "# print(type(train_ds))\n",
    "\n",
    "# print(type(train_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e530efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5062326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['morning', 'traffic', 'weather']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "num_classes = len(class_names)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbd01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 256, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "426435c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (32, 128, 256, 3)\n",
      "Label:  [2 2 0 0 1 2 1 2 0 2 1 1 2 2 0 1 0 1 2 0 0 0 1 2 2 1 1 2 1 0 2 1]\n",
      "Image shape:  (32, 128, 256, 3)\n",
      "Label:  [0 1 2 0 0 2 2 0 0 0 0 2 0 2 0 0 0 1 2 1 0 1 2 1 1 2 1 2 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(2):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57da6651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 128, 256, 3), (None,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "84a91144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위랑 성능 비교해 봐야 함\n",
    "\n",
    "# 1번 함수 사용 \n",
    "# train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "# val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# 2번 함수 사용\n",
    "# train_ds = configure_for_performance(train_ds)\n",
    "# val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ebc5ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞의 몇 개 데이터 이미지 시각화 시켜서 확인\n",
    "\n",
    "# image_batch, label_batch = next(iter(train_ds))\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(9):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "#     label = label_batch[i]\n",
    "#     plt.title(class_names[label])\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebfe14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce7fb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003921569 0.92500484\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "#print(image_batch, labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c729cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "#     layers.Conv2D(16, (3,3), padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "#     layers.MaxPooling2D(),\n",
    "#     layers.Dropout(0.2),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(num_classes)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "406036f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########## 여서부터 CNN 시작 ############\n",
    "# model = Sequential() # Sequential 모델은 각 레이어에 정확히 하나의 입력 텐서와 하나의 출력 텐서가 있는 일반 레이어 스택에 적합합니다\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(256,128,1))) # Conv2D: 필터 수, kernal_size: 필터 크기, input_shape= 입력층 (가로: 50, 세로: 50, 채널: 3) 모델에 적용\n",
    "#                                                                                       # zero paddding의 값은? (Filter Size - 1) / 2\n",
    "#                                                                                     # 굳이 알필요는 없지만 출력층의 weight의 개수는? ( Input Size + 2 * Padding - Filter Size ) / Stride + 1 ( 4 + 2 * 0 - 2 ) / 1 + 1 = 3 * 3\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2))) # 사이즈 줄이고-> 여기서 padding을 설정하면 same으로 하면 같이 유지가 돼 가장 네모 정사각형 안겹치게 해서 가장 큰 값 뽑아내기\n",
    "# model.add(Dropout(0.25)) # Dropout란? 과적합을 방지하기 위해서 학습 시에 지정된 비율만큼 임의의 입력 뉴런(1차원)을 제외시킵니다.\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu')) # 첫번째 인자 : 출력 뉴런의 수를 설정합니다, input_dim : 입력 뉴런의 수를 설정합니다\n",
    "#                                          # init : 가중치 초기화 방법 설정합니다.‘uniform’ : 균일 분포, ‘normal’ : 가우시안 분포\n",
    "# # model.add(Dropout(0.5))\n",
    "# model.add(Dense(3, activation='softmax')) # 소프트맥스 출력의 각 원소는 0.0 이상 1.0 이하의 실수입니다. 그리고 노드의 출력을 모두 합한 값이 항상 1이 됩니다.\n",
    "#                                           # 소프트맥스 함수의 좋은 점은 예측이 잘 이루어지면 1에 가까운 출력은 하나만 있고 다른 출력은 0에 가까워진다는 점입니다.\n",
    "#                                           # 하지만 예측이 잘 이루어지지 않으면 여러 레이블이 비슷한 확률을 가지게 될 수 있습니다.\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# history = model.fit_generator(train_generator, steps_per_epoch=200, epochs=50, validation_data=test_generator, validation_steps= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "634ffa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e3bc165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_9 (Rescaling)      (None, 128, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 128, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 64, 128, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 64, 128, 32)       4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 32, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 32, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 16, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 4,218,403\n",
      "Trainable params: 4,218,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd2e193c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 128, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 134, 262, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 64, 128, 64)  9472        zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 64, 128, 64)  256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 64, 128, 64)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 130, 64)  0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 64, 64)   0           zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 32, 64, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 32, 64, 64)   256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 32, 64, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 32, 64, 64)   36928       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 32, 64, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 32, 64, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 32, 64, 256)  16640       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 32, 64, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 32, 64, 256)  1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 32, 64, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 32, 64, 256)  0           batch_normalization_56[0][0]     \n",
      "                                                                 batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 32, 64, 256)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 64, 64)   16448       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 32, 64, 64)   256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 32, 64, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 64, 64)   36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 32, 64, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 32, 64, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 32, 64, 256)  16640       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 32, 64, 256)  1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 32, 64, 256)  0           batch_normalization_60[0][0]     \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 32, 64, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 64, 64)   16448       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 64, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 32, 64, 64)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 64, 64)   36928       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 64, 64)   256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 32, 64, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 64, 256)  16640       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 64, 256)  1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 32, 64, 256)  0           batch_normalization_63[0][0]     \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 32, 64, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 32, 128)  32896       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 16, 32, 128)  512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 32, 128)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 32, 128)  147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 16, 32, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 32, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 32, 512)  66048       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 32, 512)  131584      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 32, 512)  2048        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 16, 32, 512)  2048        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 16, 32, 512)  0           batch_normalization_66[0][0]     \n",
      "                                                                 batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 16, 32, 512)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 32, 128)  65664       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 16, 32, 128)  512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 16, 32, 128)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 32, 128)  147584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 16, 32, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 16, 32, 128)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 32, 512)  66048       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 16, 32, 512)  2048        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 16, 32, 512)  0           batch_normalization_70[0][0]     \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 16, 32, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 32, 128)  65664       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 32, 128)  512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 16, 32, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 32, 128)  147584      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 32, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 32, 128)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 32, 512)  66048       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 16, 32, 512)  2048        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 16, 32, 512)  0           batch_normalization_73[0][0]     \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 32, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 32, 128)  65664       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 16, 32, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 32, 128)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 32, 128)  147584      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 32, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 32, 128)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 32, 512)  66048       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 32, 512)  2048        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 16, 32, 512)  0           batch_normalization_76[0][0]     \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 16, 32, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 16, 256)   131328      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 16, 256)   1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 16, 256)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 16, 256)   590080      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 16, 256)   1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 16, 256)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 16, 1024)  263168      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 16, 1024)  525312      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 16, 1024)  4096        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 16, 1024)  4096        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 16, 1024)  0           batch_normalization_79[0][0]     \n",
      "                                                                 batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 16, 1024)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 16, 256)   262400      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 16, 256)   1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 16, 256)   0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 16, 256)   590080      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 16, 256)   1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 16, 256)   0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 16, 1024)  263168      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 16, 1024)  4096        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 8, 16, 1024)  0           batch_normalization_83[0][0]     \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 16, 1024)  0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 16, 256)   262400      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 16, 256)   1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 16, 256)   0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 16, 256)   590080      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 16, 256)   1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 16, 256)   0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 16, 1024)  263168      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 16, 1024)  4096        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 8, 16, 1024)  0           batch_normalization_86[0][0]     \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 16, 1024)  0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 16, 256)   262400      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 16, 256)   1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 16, 256)   0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 16, 256)   590080      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 16, 256)   1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 16, 256)   0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 16, 1024)  263168      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 16, 1024)  4096        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 8, 16, 1024)  0           batch_normalization_89[0][0]     \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 16, 1024)  0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 16, 256)   262400      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 16, 256)   1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 16, 256)   0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 16, 256)   590080      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 16, 256)   1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 16, 256)   0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 16, 1024)  263168      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 16, 1024)  4096        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 8, 16, 1024)  0           batch_normalization_92[0][0]     \n",
      "                                                                 activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 16, 1024)  0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 16, 256)   262400      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 16, 256)   1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 16, 256)   0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 16, 256)   590080      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 16, 256)   1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 16, 256)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 16, 1024)  263168      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 16, 1024)  4096        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 8, 16, 1024)  0           batch_normalization_95[0][0]     \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 16, 1024)  0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 8, 512)    524800      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 4, 8, 512)    2048        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 4, 8, 512)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 8, 512)    2359808     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 4, 8, 512)    2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 8, 512)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 8, 2048)   1050624     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 8, 2048)   2099200     activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 4, 8, 2048)   8192        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 4, 8, 2048)   8192        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 4, 8, 2048)   0           batch_normalization_98[0][0]     \n",
      "                                                                 batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4, 8, 2048)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 4, 8, 512)    1049088     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 4, 8, 512)    2048        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 8, 512)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 4, 8, 512)    2359808     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 4, 8, 512)    2048        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 8, 512)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 8, 2048)   1050624     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 4, 8, 2048)   8192        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 4, 8, 2048)   0           batch_normalization_102[0][0]    \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 8, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 8, 512)    1049088     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 4, 8, 512)    2048        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 8, 512)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 8, 512)    2359808     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 4, 8, 512)    2048        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 4, 8, 512)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 4, 8, 2048)   1050624     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 4, 8, 2048)   8192        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 4, 8, 2048)   0           batch_normalization_105[0][0]    \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 4, 8, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            6147        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,593,859\n",
      "Trainable params: 23,540,739\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    " \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#data_dir = pathlib.Path('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data')\n",
    "\n",
    "#train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#val_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "#train_dir = os.path.join('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data/train')\n",
    "#val_dir = os.path.join('C:/Users/jaehee/.keras/datasets/final_log_mel_spec_data/test')\n",
    " \n",
    " \n",
    " \n",
    "#train_generator = train_datagen.flow_from_directory(train_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "#val_generator = val_datagen.flow_from_directory(val_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "\n",
    "# number of classes\n",
    "#K = 4\n",
    "K = 3\n",
    " \n",
    "input_tensor = Input(shape=(128, 256, 3), dtype='float32', name='input') # shape=(224, 224, 3)\n",
    "\n",
    "def conv1_layer(x):    \n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x)\n",
    " \n",
    "    return x   \n",
    " \n",
    "    \n",
    "def conv2_layer(x):         \n",
    "    x = MaxPooling2D((3, 3), 2)(x)     \n",
    " \n",
    "    shortcut = x\n",
    " \n",
    "    for i in range(3):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)            \n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    " \n",
    "        else:\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])   \n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            shortcut = x        \n",
    "    \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv3_layer(x):        \n",
    "    shortcut = x    \n",
    "    \n",
    "    for i in range(4):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)    \n",
    " \n",
    "            shortcut = x              \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])     \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    "            \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv4_layer(x):\n",
    "    shortcut = x        \n",
    "  \n",
    "    for i in range(6):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv5_layer(x):\n",
    "    shortcut = x    \n",
    "  \n",
    "    for i in range(3):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])  \n",
    "            x = Activation('relu')(x)      \n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)           \n",
    "            \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)       \n",
    " \n",
    "            shortcut = x                  \n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "x = conv1_layer(input_tensor)\n",
    "x = conv2_layer(x)\n",
    "x = conv3_layer(x)\n",
    "x = conv4_layer(x)\n",
    "x = conv5_layer(x)\n",
    " \n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output_tensor = Dense(K, activation='softmax')(x)\n",
    " \n",
    "resnet50 = Model(input_tensor, output_tensor)\n",
    "resnet50.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24476024",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8021c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "15/33 [============>.................] - ETA: 1:17 - loss: 0.9004 - accuracy: 0.6392"
     ]
    }
   ],
   "source": [
    "EPOCHS=3\n",
    "history = resnet50.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    #callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "resnet50.save('resnet50_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "09dc058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_avg = 0.9178\n",
      "test_avg = 0.9607\n"
     ]
    }
   ],
   "source": [
    "train_avg = np.mean(history.history['accuracy'])\n",
    "test_avg = np.mean(history.history['val_accuracy'])\n",
    "print('train_avg = {0:.4f}'.format(train_avg))\n",
    "print('test_avg = {0:.4f}'.format(test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9ded2a7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b8818408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('voice_predict_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fad99b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\jaehee\\\\Desktop\\\\jupyter_proj\\\\test_voice\\\\tvon.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-654bbba046ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# plt.imshow(gray, cmap='gray')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\jaehee\\\\Desktop\\\\jupyter_proj\\\\test_voice\\\\tvon.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mimgGray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mimgGray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_gray.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2911\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2912\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\jaehee\\\\Desktop\\\\jupyter_proj\\\\test_voice\\\\tvon.png'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# image = cv2.imread('C:\\\\Users\\\\jaehee\\\\Desktop\\\\jupyter_proj\\\\test_voice\\\\tvon.png')\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "# plt.imshow(gray, cmap='gray')\n",
    "# plt.show()\n",
    "img = Image.open('C:\\\\Users\\\\jaehee\\\\Desktop\\\\jupyter_proj\\\\test_voice\\\\tvon.png')\n",
    "imgGray = img.convert('L')\n",
    "imgGray.save('test_gray.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d32c9ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "image_path = 'C:\\\\Users\\\\jaehee\\\\Desktop\\\\jupyter_proj\\\\test_voice\\\\tvon.png'\n",
    "img = image.load_img(image_path, target_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "47e1c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 256, 1) for input Tensor(\"rescaling_12_input:0\", shape=(None, 128, 256, 1), dtype=float32), but it was called on an input with incompatible shape (32, 1, 256, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer conv2d_21 is incompatible with the layer: expected axis -1 of input shape to have value 1 but received input with shape [32, 1, 256, 3]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-6d0bab07c4b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Create a batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3139\u001b[0m           expand_composites=True)\n\u001b[0;32m   3140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3142\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\jaehee\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer conv2d_21 is incompatible with the layer: expected axis -1 of input shape to have value 1 but received input with shape [32, 1, 256, 3]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "image_path = 'C:/Users/jaehee/.keras/datasets/new_gray_data/all/living_room5.png'\n",
    "img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 1) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "print(predictions)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(score)\n",
    "print(\n",
    "    \"새로운 데이터는 {} 클래스일 확률이 {:.2f}%입니다..\".format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f40eaba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c6f587e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('voice_predict_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8296b037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_3 (Rescaling)      (None, 128, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 256, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 128, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 128, 32)       4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 4,218,403\n",
      "Trainable params: 4,218,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117dcd58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
